{
    "ae_sent_config": {
        "tokenized_dataset_path": "dataset.jsonl",
        "input_padding": [0, 0],
        "target_padding": 0,
        "batch_size": 32,
        "num_buckets": 3,
        "first_bucket_boundary": 33,
        "shuffling_buffer_size": 1024,
        "weight_decay": 5e-5,
        "learning_rate": 1e-6,
        "scheduled_iterations": 100000,
        "cycle_end": 500,
        "max_rate": 1e-5,
        "last_rate": 1e-8,
        "checkpoint_path": "checkpoints",
        "log_path": "logs",
        "save_freq": "epoch",
        "log_update_freq": 1000,
        "devices": ["GPU:0", "GPU:1"]
    },
    "bert_config": {
        "vocab_size": 30000,
        "hidden_size": 768,
        "num_hidden_layers": 6,
        "num_attention_heads": 12,
        "intermediate_size": 3072
    },
    "gpt_config": {
        "vocab_size": 30000,
        "n_embd": 768,
        "n_layer": 6,
        "n_head": 12
    }
}
